{"cells":[{"cell_type":"markdown","source":["First steps for bonus"],"metadata":{"id":"Hv9jGtVvOHPz"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import math\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import random\n","import os\n","import matplotlib.pyplot as plt\n","\n","# Set random seeds for reproducibility\n","seed = 42\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","# Load CIFAR-10 data to compute mean and standard deviation\n","cifar10 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n","mean = torch.zeros(3)\n","std = torch.zeros(3)\n","for img, _ in cifar10:\n","    mean += img.mean([1, 2])\n","    std += img.std([1, 2])\n","mean /= len(cifar10)\n","std /= len(cifar10)\n","mean_tuple = tuple(mean.numpy())\n","std_tuple = tuple(std.numpy())\n","\n","# Transformations matching original code\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean_tuple, std_tuple)\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean_tuple, std_tuple)\n","])\n","\n","class PerformerLayerF0(nn.Module):\n","    def __init__(self, dim, n_heads, dropout=0.1):\n","        super().__init__()\n","        self.dim = dim\n","        self.n_heads = n_heads\n","        self.head_dim = dim // n_heads\n","        assert self.head_dim * n_heads == dim, \"dim must be divisible by n_heads\"\n","\n","        # Learnable kernel generator network\n","        # This network learns to generate features that can be transformed by both ReLU and exp\n","        # Architecture: Linear -> LayerNorm -> ReLU -> Linear\n","        # Input/output dimensions match head_dim for compatibility with attention mechanism\n","        self.kernel_net = nn.Sequential(\n","            nn.Linear(self.head_dim, self.head_dim * 2),  # Expand dimension for richer features\n","            nn.LayerNorm(self.head_dim * 2),              # Normalize for stable training\n","            nn.ReLU(),                                    # Non-linearity\n","            nn.Linear(self.head_dim * 2, self.head_dim)   # Project back to original dimension\n","        )\n","\n","        # Learnable attention parameters\n","        # epsilon: Small constant for numerical stability\n","        # tau: Temperature parameter to control feature scaling\n","        # mixture: Learnable parameter to balance between ReLU and exp kernels\n","        self.epsilon = nn.Parameter(torch.full([1], 1e-6))\n","        self.tau = nn.Parameter(torch.ones(1))\n","        self.mixture = nn.Parameter(torch.sigmoid(torch.zeros(1)))\n","\n","        # Linear projections\n","        self.to_q = nn.Linear(dim, dim)\n","        self.to_k = nn.Linear(dim, dim)\n","        self.to_v = nn.Linear(dim, dim)\n","        self.to_out = nn.Linear(dim, dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.layer_norm1 = nn.LayerNorm(dim)\n","        self.layer_norm2 = nn.LayerNorm(dim)\n","\n","    def f0_kernel(self, x):\n","       \"\"\"\n","        Learnable kernel function fθ that combines ReLU and exponential kernels\n","        This function learns the optimal balance between the two kernel types\n","        \"\"\"\n","        # Generate features using learnable network\n","        features = self.kernel_net(x)\n","        # Apply ReLU kernel transformation with learnable temperature\n","        relu_features = F.relu(features / self.tau)\n","                # Apply exp kernel transformation with learnable temperature\n","        # Clamp values to prevent numerical overflow\n","        exp_features = torch.exp(torch.clamp(features / self.tau, min=-5, max=5))\n","        # Combine both kernel types using learnable mixture parameter\n","        # mixture controls the balance between exp and ReLU attention\n","        mixed_features = (self.mixture * exp_features +           # Exponential component\n","                        (1 - self.mixture) * relu_features +      # ReLU component\n","                        self.epsilon)                             # Stability term\n","        return mixed_features\n","\n","    def forward(self, x):\n","        batch_size, seq_length, _ = x.shape\n","        residual = x\n","        x = self.layer_norm1(x)\n","\n","        # Project to q, k, v and split into heads\n","        q = self.to_q(x).view(batch_size, seq_length, self.n_heads, self.head_dim).transpose(1, 2)\n","        k = self.to_k(x).view(batch_size, seq_length, self.n_heads, self.head_dim).transpose(1, 2)\n","        v = self.to_v(x).view(batch_size, seq_length, self.n_heads, self.head_dim).transpose(1, 2)\n","\n","        # Apply f₀ kernel transformation\n","        q = self.f0_kernel(q)\n","        k = self.f0_kernel(k)\n","\n","        # Fast attention using FAVOR+\n","        scale = math.sqrt(self.head_dim)\n","        k_cumsum = k.sum(dim=2, keepdim=True)\n","        D = q @ k_cumsum.transpose(-2, -1) / scale\n","        attention = (q @ k.transpose(-2, -1) @ v) / (D + self.epsilon)\n","\n","        out = attention.transpose(1, 2).contiguous().view(batch_size, seq_length, self.dim)\n","        out = self.to_out(out)\n","        out = self.dropout(out)\n","        out = residual + out\n","        out = self.layer_norm2(out)\n","\n","        return out\n","\n","   class PerformerF0(nn.Module):\n","    def __init__(self, dim, n_heads, depth, dropout, num_classes=10):\n","        super().__init__()\n","        self.dim = dim\n","\n","        # Initial convolutional layers\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2, 2)\n","        )\n","\n","        # Embedding layer\n","        self.embedding = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(256 * 16 * 16, dim),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(dropout)\n","        )\n","\n","        # Performer layers\n","        self.performer_layers = nn.ModuleList([\n","            PerformerLayerF0(dim, n_heads, dropout=dropout) for _ in range(depth)\n","        ])\n","\n","        # Classification head\n","        self.classifier = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = self.conv_layers(x)\n","        x = self.embedding(x).unsqueeze(1)\n","        for layer in self.performer_layers:\n","            x = layer(x)\n","        x = x.squeeze(1)\n","        x = self.classifier(x)\n","        return x\n","\n","def train_model(model, trainloader, testloader, criterion, optimizer, scheduler, device, num_epochs):\n","    model.to(device)\n","    start_time = time.time()\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","\n","        # Training phase\n","        loop = tqdm(trainloader, desc=f'Epoch [{epoch+1}/{num_epochs}]', leave=False)\n","        for inputs, labels in loop:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","            # Get accuracy\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            loop.set_postfix(loss=loss.item())\n","\n","        # Validation phase\n","        model.eval()\n","        with torch.no_grad():\n","            for inputs, labels in testloader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                val_loss += criterion(outputs, labels).item()\n","\n","        scheduler.step()\n","\n","        # Calculate average losses and accuracy\n","        avg_train_loss = running_loss / len(trainloader)\n","        avg_val_loss = val_loss / len(testloader)\n","        accuracy = 100 * correct / total\n","\n","        # Print metrics\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n","\n","        # Print mixture values to observe ReLU vs exp preference\n","        mix_values = [layer.mixture.item() for layer in model.performer_layers]\n","        print(f\"Average mixture (ReLU-exp balance): {np.mean(mix_values):.3f}\")\n","\n","    training_time = time.time() - start_time\n","    print(f\"\\nTraining Time: {training_time:.2f} seconds\")\n","    return training_time\n","\n","def evaluate_model(model, testloader, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    start_time = time.time()\n","\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    inference_time = time.time() - start_time\n","    accuracy = 100 * correct / total\n","    print(f\"Accuracy: {accuracy:.2f}%, Inference Time: {inference_time:.2f} seconds\")\n","    return accuracy, inference_time\n","\n","def main():\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Data loaders\n","    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n","\n","    # Model configuration\n","    model = PerformerF0(\n","        dim=512,\n","        n_heads=16,\n","        depth=1,\n","        dropout=0.1\n","    )\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.AdamW(model.parameters(), lr=0.0005)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n","\n","    # Train and evaluate\n","    training_time = train_model(model, trainloader, testloader, criterion, optimizer, scheduler, device, num_epochs=60)\n","    accuracy, inference_time = evaluate_model(model, testloader, device)\n","\n","    # Print final mixture values to analyze learned kernel preference\n","    final_mix_values = [layer.mixture.item() for layer in model.performer_layers]\n","    print(f\"\\nFinal ReLU-exp balance per layer: {final_mix_values}\")\n","    print(f\"Average final mixture: {np.mean(final_mix_values):.3f}\")\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYFP6GYQmLKs","executionInfo":{"status":"ok","timestamp":1733719236791,"user_tz":300,"elapsed":775547,"user":{"displayName":"Ananya Rana","userId":"02991734666597253802"}},"outputId":"e834c7af-5b92-4068-ad13-3a370742298b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [1/60], Loss: 1.5384, Validation Loss: 1.1570, Accuracy: 43.30%\n","Average mixture (ReLU-exp balance): 0.442\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [2/60], Loss: 1.1242, Validation Loss: 0.9309, Accuracy: 59.80%\n","Average mixture (ReLU-exp balance): 0.416\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [3/60], Loss: 0.9719, Validation Loss: 0.8499, Accuracy: 65.48%\n","Average mixture (ReLU-exp balance): 0.403\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [4/60], Loss: 0.8806, Validation Loss: 0.7602, Accuracy: 68.93%\n","Average mixture (ReLU-exp balance): 0.393\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [5/60], Loss: 0.8119, Validation Loss: 0.7277, Accuracy: 71.41%\n","Average mixture (ReLU-exp balance): 0.386\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [6/60], Loss: 0.7145, Validation Loss: 0.6574, Accuracy: 74.82%\n","Average mixture (ReLU-exp balance): 0.382\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [7/60], Loss: 0.6794, Validation Loss: 0.6437, Accuracy: 76.13%\n","Average mixture (ReLU-exp balance): 0.381\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [8/60], Loss: 0.6499, Validation Loss: 0.6017, Accuracy: 77.17%\n","Average mixture (ReLU-exp balance): 0.376\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [9/60], Loss: 0.6266, Validation Loss: 0.5809, Accuracy: 77.93%\n","Average mixture (ReLU-exp balance): 0.374\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [10/60], Loss: 0.6083, Validation Loss: 0.5992, Accuracy: 78.54%\n","Average mixture (ReLU-exp balance): 0.369\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [11/60], Loss: 0.5469, Validation Loss: 0.5564, Accuracy: 80.69%\n","Average mixture (ReLU-exp balance): 0.368\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [12/60], Loss: 0.5286, Validation Loss: 0.5543, Accuracy: 81.49%\n","Average mixture (ReLU-exp balance): 0.368\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [13/60], Loss: 0.5193, Validation Loss: 0.5364, Accuracy: 81.77%\n","Average mixture (ReLU-exp balance): 0.366\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [14/60], Loss: 0.5026, Validation Loss: 0.5290, Accuracy: 82.39%\n","Average mixture (ReLU-exp balance): 0.366\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [15/60], Loss: 0.4967, Validation Loss: 0.5219, Accuracy: 82.69%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [16/60], Loss: 0.4610, Validation Loss: 0.4962, Accuracy: 84.07%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [17/60], Loss: 0.4499, Validation Loss: 0.5106, Accuracy: 84.21%\n","Average mixture (ReLU-exp balance): 0.365\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [18/60], Loss: 0.4372, Validation Loss: 0.5060, Accuracy: 84.64%\n","Average mixture (ReLU-exp balance): 0.365\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [19/60], Loss: 0.4329, Validation Loss: 0.4969, Accuracy: 84.89%\n","Average mixture (ReLU-exp balance): 0.365\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [20/60], Loss: 0.4258, Validation Loss: 0.4893, Accuracy: 85.03%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [21/60], Loss: 0.4024, Validation Loss: 0.4816, Accuracy: 85.81%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [22/60], Loss: 0.4010, Validation Loss: 0.4813, Accuracy: 85.96%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [23/60], Loss: 0.3927, Validation Loss: 0.4762, Accuracy: 86.32%\n","Average mixture (ReLU-exp balance): 0.365\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [24/60], Loss: 0.3887, Validation Loss: 0.4849, Accuracy: 86.35%\n","Average mixture (ReLU-exp balance): 0.365\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [25/60], Loss: 0.3855, Validation Loss: 0.4804, Accuracy: 86.40%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [26/60], Loss: 0.3722, Validation Loss: 0.4809, Accuracy: 87.05%\n","Average mixture (ReLU-exp balance): 0.365\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [27/60], Loss: 0.3726, Validation Loss: 0.4795, Accuracy: 86.97%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [28/60], Loss: 0.3705, Validation Loss: 0.4759, Accuracy: 86.90%\n","Average mixture (ReLU-exp balance): 0.365\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [29/60], Loss: 0.3685, Validation Loss: 0.4782, Accuracy: 87.11%\n","Average mixture (ReLU-exp balance): 0.365\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [30/60], Loss: 0.3635, Validation Loss: 0.4739, Accuracy: 87.41%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [31/60], Loss: 0.3590, Validation Loss: 0.4761, Accuracy: 87.43%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [32/60], Loss: 0.3517, Validation Loss: 0.4798, Accuracy: 87.51%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [33/60], Loss: 0.3558, Validation Loss: 0.4722, Accuracy: 87.61%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [34/60], Loss: 0.3539, Validation Loss: 0.4763, Accuracy: 87.58%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [35/60], Loss: 0.3565, Validation Loss: 0.4747, Accuracy: 87.63%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [36/60], Loss: 0.3519, Validation Loss: 0.4747, Accuracy: 87.55%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [37/60], Loss: 0.3505, Validation Loss: 0.4735, Accuracy: 87.84%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [38/60], Loss: 0.3485, Validation Loss: 0.4734, Accuracy: 87.78%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [39/60], Loss: 0.3479, Validation Loss: 0.4753, Accuracy: 87.82%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [40/60], Loss: 0.3470, Validation Loss: 0.4746, Accuracy: 87.90%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [41/60], Loss: 0.3469, Validation Loss: 0.4737, Accuracy: 88.04%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [42/60], Loss: 0.3452, Validation Loss: 0.4762, Accuracy: 87.95%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [43/60], Loss: 0.3464, Validation Loss: 0.4751, Accuracy: 88.00%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [44/60], Loss: 0.3458, Validation Loss: 0.4718, Accuracy: 87.78%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [45/60], Loss: 0.3403, Validation Loss: 0.4746, Accuracy: 88.03%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [46/60], Loss: 0.3459, Validation Loss: 0.4736, Accuracy: 88.00%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [47/60], Loss: 0.3449, Validation Loss: 0.4750, Accuracy: 87.81%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [48/60], Loss: 0.3425, Validation Loss: 0.4743, Accuracy: 87.99%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [49/60], Loss: 0.3450, Validation Loss: 0.4748, Accuracy: 87.80%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [50/60], Loss: 0.3401, Validation Loss: 0.4741, Accuracy: 88.12%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [51/60], Loss: 0.3408, Validation Loss: 0.4745, Accuracy: 88.10%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [52/60], Loss: 0.3464, Validation Loss: 0.4739, Accuracy: 87.93%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [53/60], Loss: 0.3439, Validation Loss: 0.4744, Accuracy: 87.97%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [54/60], Loss: 0.3403, Validation Loss: 0.4747, Accuracy: 88.03%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [55/60], Loss: 0.3419, Validation Loss: 0.4750, Accuracy: 88.02%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [56/60], Loss: 0.3441, Validation Loss: 0.4751, Accuracy: 87.94%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [57/60], Loss: 0.3423, Validation Loss: 0.4745, Accuracy: 87.83%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [58/60], Loss: 0.3446, Validation Loss: 0.4757, Accuracy: 88.07%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [59/60], Loss: 0.3418, Validation Loss: 0.4742, Accuracy: 88.16%\n","Average mixture (ReLU-exp balance): 0.364\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [60/60], Loss: 0.3414, Validation Loss: 0.4745, Accuracy: 88.00%\n","Average mixture (ReLU-exp balance): 0.364\n","\n","Training Time: 768.80 seconds\n","Accuracy: 84.84%, Inference Time: 1.43 seconds\n","\n","Final ReLU-exp balance per layer: [0.3641982674598694]\n","Average final mixture: 0.364\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1WjWiODxs08bmSsZ0hTWeSSNu3bFkJRqB","timestamp":1733727665669},{"file_id":"11AGuY8CtO_rL1w97qSOTA4m8GJjZrw1m","timestamp":1733283600851},{"file_id":"1_FH4hBWN9Vh1-EYV8oAL8jNalbtquieO","timestamp":1733280992848}],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMyht8ddsd3FVsJFD4L/BGg"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from tqdm import tqdm\n","import random\n","import os\n","import csv\n","import time\n","import itertools\n","import matplotlib.pyplot as plt"],"metadata":{"id":"2KIfyFgpd_fF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWtKh2FeZvBH","outputId":"8e2e980a-584f-422e-9542-d7712f2cca9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Dec  7 18:35:42 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   30C    P0              48W / 400W |      2MiB / 40960MiB |      0%      Default |\n","|                                         |                      |             Disabled |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["class VisionTransformer(nn.Module):\n","    def __init__(self, img_size, patch_size, in_channels, num_classes, dim, depth, heads, mlp_dim, dropout=0.1):\n","        super(VisionTransformer, self).__init__()\n","\n","        # Ensure image size divisible by patch size\n","        assert img_size % patch_size == 0, \"Image size must be divisible by patch size\"\n","        num_patches = (img_size // patch_size) ** 2\n","\n","        self.patch_embedding = nn.Conv2d(in_channels, dim, kernel_size=patch_size, stride=patch_size)\n","\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n","        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n","\n","        self.transformer = nn.ModuleList([\n","            nn.TransformerEncoderLayer(\n","                d_model=dim,\n","                nhead=heads,\n","                dim_feedforward=mlp_dim,\n","                dropout=dropout,\n","                batch_first=True\n","            ) for _ in range(depth)\n","        ])\n","\n","        # MLP head\n","        self.mlp_head = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","\n","        x = self.patch_embedding(x)  # shape: (batch_size, dim, num_patches_x, num_patches_y)\n","        x = x.flatten(2).transpose(1, 2)  # shape: (batch_size, num_patches, dim)\n","\n","        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n","        x = torch.cat((cls_tokens, x), dim=1)\n","\n","        x += self.pos_embedding\n","\n","        for layer in self.transformer:\n","            x = layer(x)\n","\n","        cls_output = x[:, 0]\n","        return self.mlp_head(cls_output)"],"metadata":{"id":"CL7uwJZaeBRr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, trainloader, criterion, optimizer, scheduler, device, num_epochs):\n","    model.to(device)\n","    start_time = time.time()\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        loop = tqdm(trainloader, desc=f'Epoch [{epoch+1}/{num_epochs}]', leave=False)\n","\n","        for inputs, labels in loop:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            loop.set_postfix(loss=loss.item())\n","\n","        scheduler.step()\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n","\n","    training_time = time.time() - start_time\n","    print(f\"Training Time: {training_time:.2f} seconds\")\n","    return training_time\n","\n","def evaluate_model(model, testloader, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    start_time = time.time()\n","\n","    with torch.no_grad():\n","        loop = tqdm(testloader, desc=\"Evaluating\", leave=False)\n","        for inputs, labels in loop:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    inference_time = time.time() - start_time\n","    accuracy = 100 * correct / total\n","    print(f\"Accuracy: {accuracy:.2f}%, Inference Time: {inference_time:.2f} seconds\")\n","    return accuracy, inference_time\n","\n","def hyperparameter_tuning(parameters_to_test, trainloader, valloader, num_epochs):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    best_accuracy = 0.0\n","    best_params = {}\n","\n","    csv_file = 'vit_tuning_results.csv'\n","    file_exists = os.path.isfile(csv_file)\n","    with open(csv_file, mode='a', newline='') as csvfile:\n","        fieldnames = [\n","            'Patch Size', 'Dim', 'Depth', 'Heads', 'MLP Dim', 'Dropout',\n","            'Learning Rate', 'Training Time (s)', 'Inference Time (s)', 'Validation Accuracy (%)'\n","        ]\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","        if not file_exists:\n","            writer.writeheader()\n","\n","        combinations = random.sample(list(itertools.product(\n","            parameters_to_test['patch_sizes'],\n","            parameters_to_test['dims'],\n","            parameters_to_test['depths'],\n","            parameters_to_test['heads'],\n","            parameters_to_test['mlp_dims'],\n","            parameters_to_test['dropouts'],\n","            parameters_to_test['learning_rates'])), 20)\n","\n","        for patch_size, dim, depth, heads, mlp_dim, dropout, lr in combinations:\n","            print(f\"Testing combination: Patch Size={patch_size}, Dim={dim}, Depth={depth}, Heads={heads}, MLP Dim={mlp_dim}, Dropout={dropout}, LR={lr}\")\n","\n","            model = VisionTransformer(\n","                img_size=32,\n","                patch_size=patch_size,\n","                in_channels=3,\n","                num_classes=10,\n","                dim=dim,\n","                depth=depth,\n","                heads=heads,\n","                mlp_dim=mlp_dim,\n","                dropout=dropout\n","            ).to(device)\n","\n","            criterion = nn.CrossEntropyLoss()\n","            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n","            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n","\n","            training_time = train_model(model, trainloader, criterion, optimizer, scheduler, device, num_epochs)\n","            accuracy, inference_time = evaluate_model(model, valloader, device)  # Evaluate on validation set\n","\n","            # Log the results\n","            writer.writerow({\n","                'Patch Size': patch_size,\n","                'Dim': dim,\n","                'Depth': depth,\n","                'Heads': heads,\n","                'MLP Dim': mlp_dim,\n","                'Dropout': dropout,\n","                'Learning Rate': lr,\n","                'Training Time (s)': training_time,\n","                'Inference Time (s)': inference_time,\n","                'Validation Accuracy (%)': accuracy\n","            })\n","\n","            if accuracy > best_accuracy:\n","                best_accuracy = accuracy\n","                best_params = {\n","                    'patch_size': patch_size,\n","                    'dim': dim,\n","                    'depth': depth,\n","                    'heads': heads,\n","                    'mlp_dim': mlp_dim,\n","                    'dropout': dropout,\n","                    'lr': lr\n","                }\n","\n","    return best_params"],"metadata":{"id":"JiJW46hIWwfN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cifar10 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n","\n","mean = torch.zeros(3)\n","std = torch.zeros(3)\n","\n","for img, _ in cifar10:\n","    mean += img.mean([1, 2])\n","    std += img.std([1, 2])\n","\n","mean /= len(cifar10)\n","std /= len(cifar10)\n","\n","mean_tuple = tuple(mean.numpy())\n","std_tuple = tuple(std.numpy())\n","\n","print(mean_tuple, std_tuple)\n","\n","# Transformations for training data with advanced augmentations\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean_tuple, std_tuple)\n","])\n","\n","# Transformations for test data\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean_tuple, std_tuple)\n","])\n","\n","# Load training and test datasets\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","\n","# Data loaders\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UMXMUPfpeBlv","outputId":"943aafe2-a7b6-43e5-ce3f-f400b02c7ec5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","(0.49421427, 0.4851322, 0.45040995) (0.20199372, 0.19911827, 0.20113052)\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["parameters_to_test = {\n","    'patch_sizes': [4, 8],\n","    'dims': [128, 256],\n","    'depths': [6, 8],\n","    'heads': [4, 8],\n","    'mlp_dims': [512, 1024],\n","    'dropouts': [0.1, 0.3],\n","    'learning_rates': [1e-3, 5e-4]\n","}\n","\n","best_params = hyperparameter_tuning(parameters_to_test, trainloader, testloader, num_epochs=10)\n","print(f\"Best Parameters: {best_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nzt2EJhzeRoA","outputId":"8ac14400-43e9-4750-e27c-bc2dd91abb5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing combination: Patch Size=8, Dim=256, Depth=6, Heads=4, MLP Dim=1024, Dropout=0.3, LR=0.001\n","Epoch [1/10], Loss: 2.0907\n","Epoch [2/10], Loss: 1.9433\n","Epoch [3/10], Loss: 1.8691\n","Epoch [4/10], Loss: 1.8081\n","Epoch [5/10], Loss: 1.7564\n","Epoch [6/10], Loss: 1.6190\n","Epoch [7/10], Loss: 1.5536\n","Epoch [8/10], Loss: 1.5191\n","Epoch [9/10], Loss: 1.4825\n","Epoch [10/10], Loss: 1.4553\n","Training Time: 113.26 seconds\n","Accuracy: 53.89%, Inference Time: 1.45 seconds\n","Testing combination: Patch Size=4, Dim=256, Depth=8, Heads=8, MLP Dim=512, Dropout=0.3, LR=0.001\n","Epoch [1/10], Loss: 2.0837\n","Epoch [2/10], Loss: 1.8654\n","Epoch [3/10], Loss: 1.7694\n","Epoch [4/10], Loss: 1.6396\n","Epoch [5/10], Loss: 1.5471\n","Epoch [6/10], Loss: 1.4047\n","Epoch [7/10], Loss: 1.3486\n","Epoch [8/10], Loss: 1.2872\n","Epoch [9/10], Loss: 1.2510\n","Epoch [10/10], Loss: 1.2113\n","Training Time: 444.40 seconds\n","Accuracy: 63.26%, Inference Time: 3.04 seconds\n","Testing combination: Patch Size=4, Dim=256, Depth=8, Heads=4, MLP Dim=1024, Dropout=0.3, LR=0.001\n","Epoch [1/10], Loss: 2.2529\n","Epoch [2/10], Loss: 2.3149\n","Epoch [3/10], Loss: 2.3093\n","Epoch [4/10], Loss: 2.3063\n","Epoch [5/10], Loss: 2.3056\n","Epoch [6/10], Loss: 2.3047\n","Epoch [7/10], Loss: 2.3065\n","Epoch [8/10], Loss: 2.3044\n","Epoch [9/10], Loss: 2.2325\n","Epoch [10/10], Loss: 2.0212\n","Training Time: 509.52 seconds\n","Accuracy: 28.54%, Inference Time: 3.80 seconds\n","Testing combination: Patch Size=4, Dim=256, Depth=6, Heads=4, MLP Dim=1024, Dropout=0.3, LR=0.0005\n","Epoch [1/10], Loss: 1.9383\n","Epoch [2/10], Loss: 1.6448\n","Epoch [3/10], Loss: 1.5230\n","Epoch [4/10], Loss: 1.4240\n","Epoch [5/10], Loss: 1.3533\n","Epoch [6/10], Loss: 1.2281\n","Epoch [7/10], Loss: 1.1792\n","Epoch [8/10], Loss: 1.1436\n","Epoch [9/10], Loss: 1.1105\n","Epoch [10/10], Loss: 1.0836\n","Training Time: 384.61 seconds\n","Accuracy: 65.11%, Inference Time: 2.90 seconds\n","Testing combination: Patch Size=8, Dim=128, Depth=8, Heads=4, MLP Dim=512, Dropout=0.3, LR=0.001\n","Epoch [1/10], Loss: 2.0017\n","Epoch [2/10], Loss: 1.7894\n","Epoch [3/10], Loss: 1.6647\n","Epoch [4/10], Loss: 1.5856\n","Epoch [5/10], Loss: 1.5388\n","Epoch [6/10], Loss: 1.4370\n","Epoch [7/10], Loss: 1.4053\n","Epoch [8/10], Loss: 1.3766\n","Epoch [9/10], Loss: 1.3480\n","Epoch [10/10], Loss: 1.3305\n","Training Time: 97.36 seconds\n","Accuracy: 58.00%, Inference Time: 1.49 seconds\n","Testing combination: Patch Size=4, Dim=128, Depth=8, Heads=4, MLP Dim=1024, Dropout=0.1, LR=0.0005\n","Epoch [1/10], Loss: 1.9796\n","Epoch [2/10], Loss: 1.7023\n","Epoch [3/10], Loss: 1.5165\n","Epoch [4/10], Loss: 1.4020\n","Epoch [5/10], Loss: 1.3103\n","Epoch [6/10], Loss: 1.1971\n","Epoch [7/10], Loss: 1.1403\n","Epoch [8/10], Loss: 1.0974\n","Epoch [9/10], Loss: 1.0534\n","Epoch [10/10], Loss: 1.0191\n","Training Time: 292.26 seconds\n","Accuracy: 66.88%, Inference Time: 2.23 seconds\n","Testing combination: Patch Size=4, Dim=256, Depth=6, Heads=8, MLP Dim=512, Dropout=0.1, LR=0.0005\n","Epoch [1/10], Loss: 1.8250\n","Epoch [2/10], Loss: 1.5058\n","Epoch [3/10], Loss: 1.3755\n","Epoch [4/10], Loss: 1.2911\n","Epoch [5/10], Loss: 1.2272\n","Epoch [6/10], Loss: 1.0900\n","Epoch [7/10], Loss: 1.0392\n","Epoch [8/10], Loss: 1.0075\n","Epoch [9/10], Loss: 0.9647\n","Epoch [10/10], Loss: 0.9428\n","Training Time: 335.99 seconds\n","Accuracy: 69.89%, Inference Time: 2.34 seconds\n","Testing combination: Patch Size=4, Dim=256, Depth=6, Heads=4, MLP Dim=512, Dropout=0.3, LR=0.0005\n","Epoch [1/10], Loss: 1.8809\n","Epoch [2/10], Loss: 1.6190\n","Epoch [3/10], Loss: 1.4977\n","Epoch [4/10], Loss: 1.4188\n","Epoch [5/10], Loss: 1.3581\n","Epoch [6/10], Loss: 1.2513\n","Epoch [7/10], Loss: 1.2130\n","Epoch [8/10], Loss: 1.1779\n","Epoch [9/10], Loss: 1.1424\n","Epoch [10/10], Loss: 1.1128\n","Training Time: 308.07 seconds\n","Accuracy: 64.64%, Inference Time: 2.22 seconds\n","Testing combination: Patch Size=4, Dim=256, Depth=8, Heads=4, MLP Dim=512, Dropout=0.3, LR=0.0005\n","Epoch [1/10], Loss: 1.9406\n","Epoch [2/10], Loss: 1.6527\n","Epoch [3/10], Loss: 1.5162\n","Epoch [4/10], Loss: 1.4401\n","Epoch [5/10], Loss: 1.3723\n","Epoch [6/10], Loss: 1.2671\n","Epoch [7/10], Loss: 1.2075\n","Epoch [8/10], Loss: 1.1758\n","Epoch [9/10], Loss: 1.1431\n","Epoch [10/10], Loss: 1.1005\n","Training Time: 407.61 seconds\n","Accuracy: 64.67%, Inference Time: 2.87 seconds\n","Testing combination: Patch Size=4, Dim=256, Depth=6, Heads=4, MLP Dim=1024, Dropout=0.3, LR=0.001\n","Epoch [1/10], Loss: 2.1049\n","Epoch [2/10], Loss: 1.9081\n","Epoch [3/10], Loss: 1.8095\n","Epoch [4/10], Loss: 1.7481\n","Epoch [5/10], Loss: 1.6949\n","Epoch [6/10], Loss: 1.5764\n","Epoch [7/10], Loss: 1.5152\n","Epoch [8/10], Loss: 1.4716\n","Epoch [9/10], Loss: 1.4254\n","Epoch [10/10], Loss: 1.3759\n","Training Time: 383.08 seconds\n","Accuracy: 54.92%, Inference Time: 2.90 seconds\n","Testing combination: Patch Size=4, Dim=256, Depth=6, Heads=8, MLP Dim=512, Dropout=0.3, LR=0.0005\n","Epoch [1/10], Loss: 1.8690\n","Epoch [2/10], Loss: 1.5716\n","Epoch [3/10], Loss: 1.4633\n","Epoch [4/10], Loss: 1.3787\n","Epoch [5/10], Loss: 1.3234\n","Epoch [6/10], Loss: 1.2121\n","Epoch [7/10], Loss: 1.1656\n","Epoch [8/10], Loss: 1.1299\n","Epoch [9/10], Loss: 1.1030\n","Epoch [10/10], Loss: 1.0711\n","Training Time: 335.47 seconds\n","Accuracy: 66.35%, Inference Time: 2.35 seconds\n","Testing combination: Patch Size=8, Dim=128, Depth=6, Heads=8, MLP Dim=1024, Dropout=0.3, LR=0.001\n","Epoch [1/10], Loss: 2.0838\n","Epoch [2/10], Loss: 1.8457\n","Epoch [3/10], Loss: 1.7241\n","Epoch [4/10], Loss: 1.6236\n","Epoch [5/10], Loss: 1.5653\n","Epoch [6/10], Loss: 1.4619\n","Epoch [7/10], Loss: 1.4204\n","Epoch [8/10], Loss: 1.3995\n","Epoch [9/10], Loss: 1.3731\n","Epoch [10/10], Loss: 1.3545\n","Training Time: 95.33 seconds\n","Accuracy: 58.08%, Inference Time: 1.61 seconds\n","Testing combination: Patch Size=8, Dim=256, Depth=6, Heads=4, MLP Dim=512, Dropout=0.1, LR=0.0005\n","Epoch [1/10], Loss: 1.8203\n","Epoch [2/10], Loss: 1.5872\n","Epoch [3/10], Loss: 1.4995\n","Epoch [4/10], Loss: 1.4385\n","Epoch [5/10], Loss: 1.3928\n","Epoch [6/10], Loss: 1.2795\n","Epoch [7/10], Loss: 1.2374\n","Epoch [8/10], Loss: 1.2096\n","Epoch [9/10], Loss: 1.1770\n","Epoch [10/10], Loss: 1.1454\n","Training Time: 96.54 seconds\n","Accuracy: 62.86%, Inference Time: 1.51 seconds\n","Testing combination: Patch Size=8, Dim=256, Depth=6, Heads=4, MLP Dim=512, Dropout=0.3, LR=0.001\n","Epoch [1/10], Loss: 2.0392\n","Epoch [2/10], Loss: 1.8741\n","Epoch [3/10], Loss: 1.7850\n","Epoch [4/10], Loss: 1.7150\n","Epoch [5/10], Loss: 1.6807\n","Epoch [6/10], Loss: 1.5622\n","Epoch [7/10], Loss: 1.5098\n","Epoch [8/10], Loss: 1.4862\n","Epoch [9/10], Loss: 1.4561\n","Epoch [10/10], Loss: 1.4290\n","Training Time: 96.55 seconds\n","Accuracy: 54.99%, Inference Time: 1.43 seconds\n","Testing combination: Patch Size=4, Dim=256, Depth=8, Heads=8, MLP Dim=512, Dropout=0.1, LR=0.0005\n","Epoch [1/10], Loss: 1.9102\n","Epoch [2/10], Loss: 1.5693\n","Epoch [3/10], Loss: 1.4079\n","Epoch [4/10], Loss: 1.3137\n","Epoch [5/10], Loss: 1.2350\n","Epoch [6/10], Loss: 1.1063\n","Epoch [7/10], Loss: 1.0491\n","Epoch [8/10], Loss: 1.0140\n","Epoch [9/10], Loss: 0.9636\n","Epoch [10/10], Loss: 0.9340\n","Training Time: 444.53 seconds\n","Accuracy: 70.32%, Inference Time: 3.03 seconds\n","Testing combination: Patch Size=8, Dim=128, Depth=8, Heads=4, MLP Dim=1024, Dropout=0.3, LR=0.0005\n","Epoch [1/10], Loss: 1.9931\n","Epoch [2/10], Loss: 1.7821\n","Epoch [3/10], Loss: 1.6752\n","Epoch [4/10], Loss: 1.5787\n","Epoch [5/10], Loss: 1.5151\n","Epoch [6/10], Loss: 1.4155\n","Epoch [7/10], Loss: 1.3888\n","Epoch [8/10], Loss: 1.3664\n","Epoch [9/10], Loss: 1.3361\n","Epoch [10/10], Loss: 1.3180\n","Training Time: 98.26 seconds\n","Accuracy: 56.84%, Inference Time: 1.40 seconds\n","Testing combination: Patch Size=8, Dim=128, Depth=6, Heads=8, MLP Dim=512, Dropout=0.1, LR=0.001\n","Epoch [1/10], Loss: 1.8626\n","Epoch [2/10], Loss: 1.5944\n","Epoch [3/10], Loss: 1.5001\n","Epoch [4/10], Loss: 1.4346\n","Epoch [5/10], Loss: 1.3887\n","Epoch [6/10], Loss: 1.2836\n","Epoch [7/10], Loss: 1.2381\n","Epoch [8/10], Loss: 1.2118\n","Epoch [9/10], Loss: 1.1881\n","Epoch [10/10], Loss: 1.1646\n","Training Time: 94.04 seconds\n","Accuracy: 62.56%, Inference Time: 1.44 seconds\n","Testing combination: Patch Size=8, Dim=256, Depth=8, Heads=4, MLP Dim=1024, Dropout=0.3, LR=0.0005\n","Epoch [1/10], Loss: 2.0180\n","Epoch [2/10], Loss: 1.7742\n","Epoch [3/10], Loss: 1.6553\n","Epoch [4/10], Loss: 1.5745\n","Epoch [5/10], Loss: 1.5149\n","Epoch [6/10], Loss: 1.4125\n","Epoch [7/10], Loss: 1.3706\n","Epoch [8/10], Loss: 1.3354\n","Epoch [9/10], Loss: 1.3117\n","Epoch [10/10], Loss: 1.2888\n","Training Time: 145.97 seconds\n","Accuracy: 57.64%, Inference Time: 1.45 seconds\n","Testing combination: Patch Size=8, Dim=128, Depth=6, Heads=8, MLP Dim=512, Dropout=0.1, LR=0.0005\n","Epoch [1/10], Loss: 1.8292\n","Epoch [2/10], Loss: 1.5721\n","Epoch [3/10], Loss: 1.4747\n","Epoch [4/10], Loss: 1.4048\n","Epoch [5/10], Loss: 1.3608\n","Epoch [6/10], Loss: 1.2738\n","Epoch [7/10], Loss: 1.2384\n","Epoch [8/10], Loss: 1.2117\n","Epoch [9/10], Loss: 1.1941\n","Epoch [10/10], Loss: 1.1665\n","Training Time: 93.18 seconds\n","Accuracy: 61.64%, Inference Time: 1.40 seconds\n","Testing combination: Patch Size=8, Dim=256, Depth=8, Heads=8, MLP Dim=1024, Dropout=0.1, LR=0.001\n","Epoch [1/10], Loss: 2.3342\n","Epoch [2/10], Loss: 2.3138\n","Epoch [3/10], Loss: 2.3045\n","Epoch [4/10], Loss: 2.3071\n","Epoch [5/10], Loss: 2.3014\n","Epoch [6/10], Loss: 2.2978\n","Epoch [7/10], Loss: 2.3040\n","Epoch [8/10], Loss: 2.3041\n","Epoch [9/10], Loss: 2.3042\n","Epoch [10/10], Loss: 2.3040\n","Training Time: 156.15 seconds\n","Accuracy: 13.00%, Inference Time: 1.55 seconds\n","Best Parameters: {'patch_size': 4, 'dim': 256, 'depth': 8, 'heads': 8, 'mlp_dim': 512, 'dropout': 0.1, 'lr': 0.0005'}\n"]}]},{"cell_type":"code","source":["# best_params = {}\n","# best_params['patch_size'] = 4\n","# best_params['dim'] = 256\n","# best_params['depth'] = 8\n","# best_params['heads'] = 8\n","# best_params['mlp_dim'] = 512\n","# best_params['dropout'] = 0.1\n","# best_params['lr'] = 0.0005"],"metadata":{"id":"ZrIfpq3xXdep"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train best model\n","def final_model_evaluation(best_params, trainloader, testloader, num_epochs):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Initialization\n","    final_model = VisionTransformer(\n","        img_size=32,\n","        patch_size=best_params['patch_size'],\n","        in_channels=3,\n","        num_classes=10,\n","        dim=best_params['dim'],\n","        depth=best_params['depth'],\n","        heads=best_params['heads'],\n","        mlp_dim=best_params['mlp_dim'],\n","        dropout=best_params['dropout']\n","    ).to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['lr'], weight_decay=1e-4)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n","\n","    training_start_time = time.time()\n","    train_model(final_model, trainloader, criterion, optimizer, scheduler, device, num_epochs)\n","    training_time = time.time() - training_start_time\n","\n","    # Evaluation\n","    test_accuracy, test_inference_time = evaluate_model(final_model, testloader, device)\n","\n","    print(f\"Final Model Evaluation:\")\n","    print(f\"Training Time: {training_time:.2f} seconds\")\n","    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n","    print(f\"Test Inference Time: {test_inference_time:.2f} seconds\")\n","\n","    return {\n","        'training_time': training_time,\n","        'test_accuracy': test_accuracy,\n","        'test_inference_time': test_inference_time\n","    }\n","\n","final_metrics = final_model_evaluation(best_params, trainloader, testloader, num_epochs=31)\n","print(final_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NiD-cvB7eRhw","outputId":"257b1650-a777-4dca-a5fe-13c1783bf10b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/31], Loss: 1.8439\n","Epoch [2/31], Loss: 1.5073\n","Epoch [3/31], Loss: 1.3594\n","Epoch [4/31], Loss: 1.2673\n","Epoch [5/31], Loss: 1.1837\n","Epoch [6/31], Loss: 1.0479\n","Epoch [7/31], Loss: 0.9964\n","Epoch [8/31], Loss: 0.9600\n","Epoch [9/31], Loss: 0.9200\n","Epoch [10/31], Loss: 0.8838\n","Epoch [11/31], Loss: 0.8165\n","Epoch [12/31], Loss: 0.7810\n","Epoch [13/31], Loss: 0.7585\n","Epoch [14/31], Loss: 0.7372\n","Epoch [15/31], Loss: 0.7188\n","Epoch [16/31], Loss: 0.6744\n","Epoch [17/31], Loss: 0.6539\n","Epoch [18/31], Loss: 0.6449\n","Epoch [19/31], Loss: 0.6300\n","Epoch [20/31], Loss: 0.6202\n","Epoch [21/31], Loss: 0.5953\n","Epoch [22/31], Loss: 0.5855\n","Epoch [23/31], Loss: 0.5813\n","Epoch [24/31], Loss: 0.5730\n","Epoch [25/31], Loss: 0.5607\n","Epoch [26/31], Loss: 0.5511\n","Epoch [27/31], Loss: 0.5481\n","Epoch [28/31], Loss: 0.5413\n","Epoch [29/31], Loss: 0.5388\n","Epoch [30/31], Loss: 0.5383\n","Epoch [31/31], Loss: 0.5306\n","Training Time: 1724.29 seconds\n","Inference Time: 5.04 seconds\n","\n","Final Model Evaluation:\n","Training Time: 1724.29 seconds\n","Test Accuracy: 84.79%\n","Test Inference Time: 5.04 seconds\n","{'training_time': 1724.2882431221008, 'test_accuracy': 84.79, 'test_inference_time': 5.0388250255584717}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PryIz82MduX2"},"execution_count":null,"outputs":[]}]}